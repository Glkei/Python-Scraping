id,comment
0,More than 3 years have passed since last update.
1,"スクレイピング(Scraping)とは、Webサイトから任意の情報を検索し抽出する技術のことです。
また、Web上のデータの取得だけではなく、構造も解析できます。"
2,スクレイピングを行う前に、確認するべき点や、作業中に気を付ける必要がある点がいくつかかありますので説明します。
3,"１）APIが存在するかどうか
APIを提供しているサービスがあればそちらを使い、データを取得しましょう。
それでも、データが不十分だったりなどの問題があるのであればスクレイピングを検討します。"
4,"２）取得後のデータの用途に関して
取得後のデータを使う場合には、注意が必要です。
取得先のデータは自分以外の著作物にあたり、著作権法に抵触しないように考慮する必要があるためです。"
5,"私的利用のための複製(第30条)
http://www.houko.com/00/01/S45/048.HTM#030"
6,"情報解析のための複製等(第47条の7)
http://www.houko.com/00/01/S45/048.HTM#047-6"
7,"また、特に問題となる3つの権利として以下が挙げられます。
1) 複製権:"
8,"製権は、著作権に含まれる権利のひとつで、著作権法第21条で規定されています。（第21条「著作者は、その著作物を複製する権利を専有する。」）
複製とは、作品を複写したり、録画・録音したり、印刷や写真にしたり、模写（書き写し）したりすること、そしてスキャナーなどにより電子的に読み取ること、また保管することなどを言います。
引用先: https://www.jrrc.or.jp/guide/outline.html"
9,2) 翻案権:
10,"翻訳権・翻案権は、著作権法第二十七条に規定されている著作財産権です。第二十七条では｢著作者は、その著作物を翻訳し、編曲し、若しくは変形し、又は脚色し、映画化し、その他翻案する権利を専有する｣（『社団法人著作権情報センター』　http://www.cric.or.jp/db/article/a1.html#021より）と明記されています。反対に見ると、これらを著作者の許諾なしに行うと、著作権の侵害になるということです。
引用先:　http://www.iprchitekizaisan.com/chosakuken/zaisan/honyaku_honan.html"
11,3) 公衆送信権:
12,"公衆送信権は、著作権法第二十三条において規定される著作財産権です。この第二十三条では「著作者は、その著作物について、公衆送信（自動公衆送信の場合にあっては、送信可能化を含む。）を行う権利を占有する。」「著作者は、公衆送信されるその著作物を受信装置を用いて公に伝達する権利を占有する。」と明記されています。
引用先:　http://www.iprchitekizaisan.com/chosakuken/zaisan/kousyusoushin.html"
13,"また上記を注意しながら、実際にスクレピングを行う際に、書いたコードによってサーバに負荷がかからないようにしましょう。
過度なアクセスはサーバに負担をかけてしまい攻撃だとみなされてしまい、最悪の場合一定期間サービスを利用できなくなってしまう可能性があります。
さらには、システムにアクセス障害が発生し、利用者の一人が逮捕された事件もありますので、常識の範囲内での使用してください。
https://ja.wikipedia.org/wiki/岡崎市立中央図書館事件"
14,以上を踏まえた上で、次に進んでいきましょう。
15,"Webスクレイピングを実践する際にHTMLの基礎を知っておくと便利です。
なぜかというと、HTMLで使われるタグ（<html>や<div>、<p>）を指定してデータを取得するからです。"
16,ちょっと例をあげてみましょう。
17,上記のコードをブラウザ上で見ると
18,
19,このようなページがでてきます。
20,このページ上で使われているHTMLタグについて解説していきましょう。
21,上記で説明したタグ以外にも種類はたくさんあります。どのようなタグかきになる場合にはその都度調べてみましょう。
22,HTMLのタグについて理解できたので、さっそくスクレイピングをしてみましょう。
23,"1.Webページを取得する
2.プログラムで、指定したタグを検索し抽出する（スクレイピング）
3.スクレイピングして得たデータを整形し保存or表示する"
24,以上の手順がスクレイピングの基本手順です。
25,PythonでWebスクレイピングする場合にはさまざまなライブラリを使っていきます。
26,"・Requests
Webページを取得する際に使います。"
27,"・BeautifulSoup4
取得したWebページを解析し、タグの検索、データの整形をします。"
28,上記のライブラリを使ってWebスクレイピングをしていきます。
29,スクレイピングをする前にPythonでWebページのHTMLをとってくる必要があります。
30,各行の説明をしていきましょう。
31,"この行ではhttp://test.neet-ai.comからHTMLをとってきてます。
とってきたHTMLはresponse変数に入ります。"
32,responseという変数はtextをつけないとBeautifulSoupで使えません。
33,"百聞は一見にしかずでプログラムをみていきましょう。
4行目までは先ほどの「Pythonでスクレイピングする準備」と変わりありません。
5行目からがスクレイピングのプログラムとなりますので各行を解説していきましょう。"
34,"ここではsoupという変数を用意し、取ってきたHTMLデータをスクレイピングできる形にしています。
カッコ内の'lxml'というのは 「lxmlというツールでresponse.textを変換するよ」 という意味です。"
35,取ってきたHTMLデータを変換できたら、BeautifulSoupの決まった型で指定してあげれば指定のデータを抽出することができます。
36,"このプログラムを順を追って解説していきましょう。
soup変数の中からtitleというタグを探し、titleタグ内の文字列をstring形式で出力するという感じです。
ここはちょっとプログラム的に理解しにくいので直感的に理解した方がいいかもしれません。
このままでは理解しにくいので以下のような感じでイメージしていただければ幸いです。"
37,
38,さらに詳しい形式などはここで紹介すると時間が足りないので下記URLをご参考にしてください。
39,Beautiful Soupドキュメント
40,このプログラムを実行することによって以下の結果が出れば成功です。
41,"まずはじめに、HTMLでリンクを表すには<a></a>タグが使われます。
この場合は、aタグ内のURLを取得したいので、string形式は使えません。"
42,"get()という関数を使うことによってリンクが貼ってあるhrefを取得することができます。
get()関数はこの先頻繁に使う上に、便利なのでぜひ覚えておきましょう。"
43,"これまで参照していたページはaタグが１つのみでした。
ではaタグが複数あるページではどうスクレイピングすればよいのでしょう？
まずはじめにaタグが複数あるページで以前のプログラムを実行してみましょう。
ページを取得する行のURLを変えましょう。"
44,"実行してみると、neet-AIのリンクしか表示されませんね。
これは、soup.a.get('href')で最初に見つかったaタグしか抽出していないからです。
全てのaタグを抽出したい場合には以下のようになります。"
45,各行を解説していきましょう。
46,ここで全てのaタグを抽出し、一度linksというリストに入れています。
47,"リスト型なので、forで回してあげると１個ずつ操作が可能になります。
操作が可能になったlink変数にget()関数を使ってあげることによって各URLを取得することができます。
この一度全てのタグを取得し、操作できるようにforで回す手法も今後よく使うので覚えておきましょう。"
48,"これまでは、タグにidやclassは記載されていませんでした。
しかし、一般的なサイトではWebデザインをしやすいようにまたはプログラムの可読性を高めるためにタグにidやclassを設定します。
idやclassが設定されたからといって、スクレイピングが格段と難しくなるわけではありません。
逆に「この内容だけをスクレイピングしたい！」と言った場面で楽になるかもしれません。"
49,"例えば上記のようなサイトがあるとします。
aのタグをみてもらえればわかりますが、全てにidが付与されています。
この時にtwitterのURLを取得したいといった場合にはこう記述することができます。"
50,findの２番目にid名を指定してやると簡単に取ることができます。
51,次はclassにしてみます。
52,"ここで注意してほしいのは、classではなく、class_です。
pythonではあらかじめ予約語（言語仕様上特別な意味を持った語）としてclassが登録されているからです。
これを回避するために、BeautifulSoupライブラリ作成者はアンダーバーをつけたのでしょう。"
53,"これまでのWebスクレイピング基礎は、こちらがWebスクレイピングをしやすいように設計したHTMLページです。
しかし、一般のWebサイトではスクレイピングするために設計はされていないので、とても複雑な構造になっている場合があります。"
54,とても複雑になっているゆえにスクレイピング以外にもWebページの特性などのスクレイピング以外の知識が必要となってきます。
55,応用編では複雑なサイトもコツを掴めばある程度はスクレイピングできるようになるので、応用編でノウハウを培っていきましょう。
56,"この手法はかなり重宝します。
niftyニュースを例に取って説明していきます。"
57,"例えばITカテゴリでページ送りできるページがあります。
実際に下の２番目を押してページ送りしてみましょう。"
58,"再びURLをみて見ると、
https://news.nifty.com/technology/2
となります。"
59,それでは次に３ページ目に移動してみましょう。
60,"３ページ目ではこのようなURLです。
https://news.nifty.com/technology/3"
61,"サーバサイドの開発をしたことがある方ならわかると思いますが大抵、ページ送りのページを作る際には
URL末尾やパラメータにページ数を入れて、ページを更新していきます。"
62,この仕組みを利用すれば、URLの数字を入れ替えるだけでページ送りをすることができます。
63,試しに末尾を好きな数字に変えてみてください。その数字に飛べると思います。（限界はありますが）
64,それでは試しにプログラム上で１ページ目から１０ページ目までの検索結果をスクレイピングするプログラムを作ってみましょう。
65,"このようになります。
検索結果や連番になっているURLをスクレイピングする際はこの手法が便利です。"
66,"https://search.nifty.com/imagesearch/search?
今回はニフティ画像検索で検索した結果をスクレイピングして大量の画像をダウンロードしていきます。
この章では画像のダウンロードの仕方とYahoo画像検索からどうやって画像のURLを取得するか学んでいきます。"
67,"画像スクレイピングをする前にまず画像のダウンロードの仕組みとしては画像の性質を知る必要があります。
みなさまは画像をテキストエディタなどで開いたことはありますでしょうか。
開いたことがある方はわかると思いますが、写真やデータなどは全て数字で構成されています。"
68,その数字を画像ビューアなどが解析して画像に変換しているわけですね。
69,"話がそれましたが、画像が数字で構成されているならその数字を全てコピーできれば写真をダウンロードすることは可能になります。
詳しいプログラムに関しては画像ダウンロード編で説明いたします。"
70,"大雑把なプログラムの流れとしては
①あるキーワードで取得した検索結果画面をスクレイピングし画像URLを取得する。
②画像URL先に画像のデータ（文字）があるのでそれをコピーする。
③コピーしたデータを自分のコンピュータに貼り付ける。"
71,になります。
72,"事前準備でも説明したとおり画像をダウンロードするにはまず画像のURLが必要です。
まず始めにニフティ画像検索で「猫」と検索し、検索結果画面を見てみましょう。
URLをみてみると、「q=猫」というのがありますね。「q=」が検索するキーワードのパラメータです。
"
73,"検索結果ページでは２０枚の写真が出て来ますね。
今回はこの２０枚の画像URLをとってみましょう。"
74,"ソースコードをみてみましょう。
"
75,"写真はimgタグで貼り付けられているのでimgと検索してみると、約１４０件ヒットします。
１４０件中２０件は私たちが求めている画像URLです。
該当する２０件以外排除するにはどんどん条件を追加していきます。"
76,"img srcで検索してみましょう。
"
77,これだけで結構近づきましたね。しかしまだ邪魔な要素が残っています。
78,"ここで一旦該当する２０件の画像URL(src)をみてみましょう。
お分かりの通り「https://msp.c.yimg.jp/」というURLから全て始まっていますね。"
79,"それでは「https://msp.c.yimg.jp/」で検索してみましょう。
"
80,ピッタリ２０件ですね！
81,該当する２０件を絞ることができたのでこれを参考にプログラムを作成していきます。
82,このプログラムの肝となるのは
83,"です。
find_allの第２引数では正規表現のオブジェクトを渡すこともできます。
ここでは先頭が「https://msp.c.yimg.jp/yjimage」で始まるsrcを探しています。"
84,"画像をダウンロードする際にはページ先画像のデータ（文字）をコピーします。
まず、ページ先画像のデータを取得するにはrequests内の.contentで取得できます。"
85,"次にコンピュータにファイルとして書き込むにはopen()と.writeで書き込むことができます。
これでプログラムを組んでみるとこんな感じになります。"
86,ファイルを生成（開く）ところでは、
87,世界で１つのIDを作ってくれるuuidというライブラリを作り、ファイル名が被らないようにしています。
88,ファイルを作り終わったところで、画像のデータを書き込んでいきます。
89,"これまでの知識を活かし、１キーワードごとに１００枚の画像をスクレイピングしていきます。
ニフティの画像検索では検索結果画面１ページにつき２０枚の写真が取れます。
なので、５ページ分取得してあげましょう。"
90,"しかしニフティ画像検索ではどのようにしてページ移動をするのでしょうか。
ニフティニュースではページの末尾の数字を変えればいいのですが、ページ移動をしてみると、ニフティ画像検索の場合は「start=」の数値を変えると移動できます。"
91,もう１ページ移動してみましょう。次は４０になりましたね。２０ごと数値を変えてやればページ移動が可能になることがわかりました。
92,これらの情報を元にプログラムを作成していきましょう。
93,サンプルプログラム
